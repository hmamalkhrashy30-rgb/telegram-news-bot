import os
import logging
import asyncio
import aiohttp
import aiohttp.client_exceptions
from bs4 import BeautifulSoup
from telegram import Bot, error
from flask import Flask, jsonify
import threading
import time
import hashlib
from datetime import datetime
import xml.etree.ElementTree as ET
import re

# ========== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ==========
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
# Ù…Ù‡Ù…: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø¹Ø±Ù Ø§Ù„Ù‚Ù†Ø§Ø© (ÙŠØ¨Ø¯Ø£ Ø¨Ù€ @) ÙˆÙ„ÙŠØ³ Ø±Ø§Ø¨Ø·
CHANNEL_USERNAME = os.getenv('CHANNEL_USERNAME', '@DO_IUi')
CHECK_INTERVAL = int(os.getenv('CHECK_INTERVAL', '600'))  # 10 Ø¯Ù‚Ø§Ø¦Ù‚

if not TELEGRAM_BOT_TOKEN:
    raise ValueError("âŒ TELEGRAM_BOT_TOKEN ØºÙŠØ± Ù…Ø­Ø¯Ø¯.")

# ØªÙ†Ø¸ÙŠÙ Ù…Ø¹Ø±Ù Ø§Ù„Ù‚Ù†Ø§Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø±Ø§Ø¨Ø·Ø§Ù‹
if CHANNEL_USERNAME.startswith('http'):
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±Ù Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
    match = re.search(r't\.me/(\w+)', CHANNEL_USERNAME)
    if match:
        CHANNEL_USERNAME = f"@{match.group(1)}"
elif not CHANNEL_USERNAME.startswith('@'):
    CHANNEL_USERNAME = f"@{CHANNEL_USERNAME}"

logging.info(f"ğŸ“¢ Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù…Ø¶Ø¨ÙˆØ·Ø©: {CHANNEL_USERNAME}")

# ========== Flask App ==========
app = Flask(__name__)

# ========== Ù…ØµØ§Ø¯Ø± RSS Ù…Ø¨Ø§Ø´Ø±Ø© (Ø¨Ø¯ÙˆÙ† Brotli issues) ==========
RSS_FEEDS = [
    ("Ø§Ù‚ØªØµØ§Ø¯", "https://www.investing.com/rss/news_285.rss"),
    ("Ø£Ø³ÙˆØ§Ù‚", "https://feeds.finance.yahoo.com/rss/2.0/headline?s=^GSPC,^DJI,^IXIC&region=US&lang=en-US"),
    ("Ù†ÙØ·", "https://www.nasdaq.com/feed/rssoutbound?symbol=CL%3DF"),
    ("Ø°Ù‡Ø¨", "https://www.nasdaq.com/feed/rssoutbound?symbol=GC%3DF"),
    ("Ø¹Ù…Ù„Ø§Øª", "https://www.ecb.europa.eu/rss/fxref-usd.html"),
    ("ÙÙŠØ¯Ø±Ø§Ù„ÙŠ", "https://www.federalreserve.gov/feeds/press_all.xml"),
]

KEYWORDS = {
    'ÙØ§Ø¦Ø¯Ø©': ['interest rate', 'fed', 'central bank', 'ÙØ§Ø¦Ø¯Ø©', 'rates', 'monetary'],
    'ØªØ¶Ø®Ù…': ['cpi', 'inflation', 'ØªØ¶Ø®Ù…', 'Ø£Ø³Ø¹Ø§Ø±', 'prices', 'consumer'],
    'Ø¨Ø·Ø§Ù„Ø©': ['unemployment', 'jobs', 'Ø¨Ø·Ø§Ù„Ø©', 'ÙˆØ¸Ø§Ø¦Ù', 'employment', 'hiring'],
    'Ù†Ø§ØªØ¬': ['gdp', 'growth', 'Ù†Ø§ØªØ¬', 'Ø§Ù‚ØªØµØ§Ø¯', 'economy', 'economic'],
    'Ù†ÙØ·': ['oil', 'crude', 'Ø¨ØªØ±ÙˆÙ„', 'Ù†ÙØ·', 'Ø£ÙˆØ¨Ùƒ', 'opec', 'energy'],
    'Ø°Ù‡Ø¨': ['gold', 'Ø°Ù‡Ø¨', 'Ù…Ø¹Ø¯Ù†', 'precious', 'bullion', 'metal'],
    'Ø­Ø±Ø¨': ['war', 'conflict', 'Ø­Ø±Ø¨', 'ØµØ±Ø§Ø¹', 'tension', 'military'],
    'Ø¹Ù‚ÙˆØ¨Ø§Øª': ['sanctions', 'Ø¹Ù‚ÙˆØ¨Ø§Øª', 'embargo', 'ban', 'restrictions'],
}

# ØªØ®Ø²ÙŠÙ†
sent_articles = set()
bot_started = False

@app.route('/')
def home():
    return jsonify({
        "status": "running",
        "service": "Telegram News Bot",
        "channel": CHANNEL_USERNAME,
        "bot_started": bot_started,
        "articles_sent": len(sent_articles),
        "endpoints": {
            "health": "/health",
            "manual_check": "/check",
            "test_channel": "/test-channel"
        }
    })

@app.route('/health')
def health():
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }), 200

@app.route('/check')
def manual_check():
    """ÙØ­Øµ ÙŠØ¯ÙˆÙŠ Ø³Ø±ÙŠØ¹"""
    threading.Thread(target=run_quick_check).start()
    return jsonify({
        "message": "Ø¨Ø¯Ø£ Ø§Ù„ÙØ­Øµ Ø§Ù„ÙŠØ¯ÙˆÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹",
        "time": datetime.now().strftime("%H:%M:%S")
    })

@app.route('/test-channel')
def test_channel():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†Ø§Ø©"""
    async def test():
        try:
            bot = Bot(token=TELEGRAM_BOT_TOKEN)
            await bot.send_message(
                chat_id=CHANNEL_USERNAME,
                text="âœ… Ø§Ø®ØªØ¨Ø§Ø±: Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­!\n" +
                     "Ø³ÙŠØ¨Ø¯Ø£ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ù‚Ø±ÙŠØ¨Ø§Ù‹."
            )
            return jsonify({"success": True, "channel": CHANNEL_USERNAME})
        except error.BadRequest as e:
            return jsonify({"error": str(e), "channel": CHANNEL_USERNAME}), 400
        except Exception as e:
            return jsonify({"error": str(e)}), 500
    
    return asyncio.run(test())

# ========== ÙˆØ¸Ø§Ø¦Ù RSS Ù…Ø­Ø³Ù†Ø© ==========
async def fetch_rss_safe(session, url, source_name):
    """Ø¬Ù„Ø¨ RSS Ø¨Ø£Ù…Ø§Ù† Ù…Ø¹ headers Ù…Ù†Ø§Ø³Ø¨Ø©"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (compatible; RSSBot/1.0)',
        'Accept': 'application/rss+xml, application/xml, text/xml, */*',
        'Accept-Encoding': 'gzip, deflate',  # Ù„Ø§ Ù†Ø·Ù„Ø¨ brotli
    }
    
    try:
        async with session.get(url, headers=headers, timeout=15) as response:
            if response.status == 200:
                content_type = response.headers.get('Content-Type', '')
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­ØªÙˆÙ‰ XML
                if 'xml' in content_type or 'rss' in content_type or url.endswith('.xml') or url.endswith('.rss'):
                    text = await response.text()
                    return parse_rss_xml(text, source_name)
                else:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ÙƒÙ€ HTML
                    text = await response.text()
                    return parse_html_for_news(text, source_name)
                    
    except aiohttp.client_exceptions.ClientError as e:
        logging.error(f"âŒ Ø®Ø·Ø£ Ø´Ø¨ÙƒØ© ÙÙŠ {source_name}: {e}")
    except asyncio.TimeoutError:
        logging.error(f"â° timeout ÙÙŠ {source_name}")
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ {source_name}: {e}")
    
    return []

def parse_rss_xml(xml_text, source_name):
    """ØªØ­Ù„ÙŠÙ„ XML Ù„Ù€ RSS"""
    articles = []
    
    try:
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹
        xml_text = re.sub(r'encoding="[^"]+"', 'encoding="utf-8"', xml_text)
        xml_text = re.sub(r'&(?!(?:amp|lt|gt|quot|apos);)', '&amp;', xml_text)
        
        root = ET.fromstring(xml_text)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† items ÙÙŠ RSS
        items = []
        for elem in root.iter():
            if 'item' in elem.tag:
                items.append(elem)
        
        if not items:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø©
            items = root.findall('.//item') or root.findall('.//entry')
        
        for item in items[:12]:  # Ø£ÙˆÙ„ 12 ÙÙ‚Ø·
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
                title_elem = item.find('title') or item.find('{http://www.w3.org/2005/Atom}title')
                if title_elem is None:
                    continue
                    
                title = title_elem.text.strip() if title_elem.text else ""
                if not title or len(title) < 10:
                    continue
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø·
                link_elem = item.find('link') or item.find('{http://www.w3.org/2005/Atom}link')
                link = ""
                if link_elem is not None:
                    if link_elem.text:
                        link = link_elem.text.strip()
                    elif 'href' in link_elem.attrib:
                        link = link_elem.attrib['href']
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆÙ‚Øª
                date_elem = item.find('pubDate') or item.find('published') or item.find('date')
                time_text = date_elem.text.strip() if date_elem is not None and date_elem.text else "Ù‚Ø¨Ù„ Ù‚Ù„ÙŠÙ„"
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ
                desc_elem = item.find('description') or item.find('summary') or item.find('content')
                summary = desc_elem.text.strip()[:150] if desc_elem is not None and desc_elem.text else ""
                
                # ØªØµÙ†ÙŠÙ
                news_type = categorize_news(title)
                
                # Ù…Ø¹Ø±Ù‘Ù ÙØ±ÙŠØ¯
                article_id = hashlib.md5(f"{title[:40]}{source_name}".encode()).hexdigest()[:10]
                
                articles.append({
                    'id': article_id,
                    'title': title,
                    'link': link,
                    'time': time_text,
                    'summary': summary,
                    'type': news_type,
                    'source': source_name,
                    'timestamp': time.time()
                })
                
            except Exception as e:
                continue
        
        logging.info(f"âœ… RSS {source_name}: {len(articles)} Ø®Ø¨Ø±")
        
    except ET.ParseError as e:
        logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ XML Ù„Ù€ {source_name}: {e}")
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ù€ BeautifulSoup ÙƒØ¨Ø¯ÙŠÙ„
        try:
            soup = BeautifulSoup(xml_text, 'html.parser')
            items = soup.find_all(['item', 'entry'])[:10]
            for item in items:
                try:
                    title = item.find('title')
                    if title:
                        title = title.text.strip()
                        if len(title) > 10:
                            articles.append({
                                'id': hashlib.md5(title.encode()).hexdigest()[:10],
                                'title': title,
                                'link': "",
                                'time': "Ù‚Ø¨Ù„ Ù‚Ù„ÙŠÙ„",
                                'summary': "",
                                'type': categorize_news(title),
                                'source': source_name,
                                'timestamp': time.time()
                            })
                except:
                    continue
            logging.info(f"âœ… RSS (Ø¨Ø¯ÙŠÙ„) {source_name}: {len(articles)} Ø®Ø¨Ø±")
        except:
            pass
    
    return articles

def parse_html_for_news(html, source_name):
    """ØªØ­Ù„ÙŠÙ„ HTML Ù„Ø£Ø®Ø¨Ø§Ø± (ÙƒØ¨Ø¯ÙŠÙ„)"""
    soup = BeautifulSoup(html, 'html.parser')
    articles = []
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ÙˆÙŠÙ†
    headlines = []
    for tag in ['h1', 'h2', 'h3', 'h4']:
        headlines.extend(soup.find_all(tag))
    
    for headline in headlines[:15]:
        title = headline.get_text(strip=True)
        if len(title) > 20 and len(title) < 200:
            news_type = categorize_news(title)
            if news_type != "Ø¹Ø§Ù…":  # ÙÙ‚Ø· Ø§Ù„Ù…Ù‡Ù…Ø©
                articles.append({
                    'id': hashlib.md5(title.encode()).hexdigest()[:10],
                    'title': title,
                    'link': "",
                    'time': "Ø­Ø¯ÙŠØ«",
                    'summary': "",
                    'type': news_type,
                    'source': source_name,
                    'timestamp': time.time()
                })
    
    return articles

def categorize_news(title):
    """ØªØµÙ†ÙŠÙ Ø§Ù„Ø®Ø¨Ø±"""
    title_lower = title.lower()
    for category, keywords in KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in title_lower:
                return category
    return "Ø¹Ø§Ù…"

# ========== Ø¥Ø±Ø³Ø§Ù„ Ø¥Ù„Ù‰ ØªÙ„ÙŠØ¬Ø±Ø§Ù… ==========
async def send_news_to_channel(bot, article):
    """Ø¥Ø±Ø³Ø§Ù„ Ø®Ø¨Ø± Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†Ø§Ø©"""
    try:
        # Ø¥ÙŠÙ…ÙˆØ¬ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        emoji_map = {
            'ÙØ§Ø¦Ø¯Ø©': 'ğŸ¦', 'ØªØ¶Ø®Ù…': 'ğŸ“ˆ', 'Ø¨Ø·Ø§Ù„Ø©': 'ğŸ‘¥',
            'Ù†Ø§ØªØ¬': 'ğŸ“Š', 'Ù†ÙØ·': 'ğŸ›¢ï¸', 'Ø°Ù‡Ø¨': 'ğŸ’°',
            'Ø­Ø±Ø¨': 'âš”ï¸', 'Ø¹Ù‚ÙˆØ¨Ø§Øª': 'ğŸš«'
        }
        
        emoji = emoji_map.get(article['type'], 'ğŸ“°')
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        message_lines = []
        message_lines.append(f"{emoji} **{article['type'].upper()}** | {article['source']}")
        message_lines.append("")
        message_lines.append(f"{article['title']}")
        message_lines.append("")
        
        if article['summary']:
            message_lines.append(f"{article['summary']}")
            message_lines.append("")
        
        message_lines.append(f"â° {article['time']}")
        
        if article['link']:
            message_lines.append(f"ğŸ”— [Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯]({article['link']})")
        
        message = "\n".join(message_lines)
        
        # Ø¥Ø±Ø³Ø§Ù„
        await bot.send_message(
            chat_id=CHANNEL_USERNAME,
            text=message[:4000],
            parse_mode='Markdown',
            disable_web_page_preview=False
        )
        
        logging.info(f"âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„: {article['title'][:50]}...")
        sent_articles.add(article['id'])
        return True
        
    except error.BadRequest as e:
        if "Chat not found" in str(e):
            logging.error(f"âŒ Ø§Ù„Ù‚Ù†Ø§Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {CHANNEL_USERNAME}")
            logging.error("âš ï¸ ØªØ£ÙƒØ¯ Ù…Ù†:")
            logging.error("   1. Ø§Ù„Ù‚Ù†Ø§Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©")
            logging.error("   2. Ø§Ù„Ø¨ÙˆØª Ù…Ø³Ø¤ÙˆÙ„ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø©")
            logging.error("   3. Ø§Ù„Ù…Ø¹Ø±Ù ØµØ­ÙŠØ­ ÙˆÙŠØ¨Ø¯Ø£ Ø¨Ù€ @")
        else:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„: {e}")
        return False
        
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        return False

# ========== Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ==========
async def main_news_loop():
    """Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    global bot_started
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨ÙˆØª ÙˆØ§Ù„Ù‚Ù†Ø§Ø© Ø£ÙˆÙ„Ø§Ù‹
    try:
        bot = Bot(token=TELEGRAM_BOT_TOKEN)
        bot_info = await bot.get_me()
        logging.info(f"ğŸ¤– Ø§Ù„Ø¨ÙˆØª: @{bot_info.username}")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø©
        await bot.send_message(
            chat_id=CHANNEL_USERNAME,
            text="ğŸ“¢ Ø¨ÙˆØª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†!\nØ¬Ø§Ø±ÙŠ ØªØ¬Ù…ÙŠØ¹ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±..."
        )
        logging.info(f"âœ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù†Ø§Ø¬Ø­ Ø¥Ù„Ù‰: {CHANNEL_USERNAME}")
        bot_started = True
        
    except error.BadRequest as e:
        logging.error(f"âŒ ÙØ´Ù„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù‚Ù†Ø§Ø©: {e}")
        logging.error("âš ï¸ Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:")
        logging.error("   1. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ù…Ø¹Ø±Ù Ø§Ù„Ù‚Ù†Ø§Ø©")
        logging.error("   2. ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¨ÙˆØª Ù…Ø³Ø¤ÙˆÙ„ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø©")
        logging.error("   3. Ø§Ù„Ù…Ø¹Ø±Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø«Ù„: @MarketNewsArabia")
        return
    except Exception as e:
        logging.error(f"âŒ ÙØ´Ù„ Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª: {e}")
        return
    
    # Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    async with aiohttp.ClientSession() as session:
        while True:
            try:
                logging.info("=" * 60)
                logging.info(f"ğŸ”„ Ø¨Ø¯Ø¡ ÙØ­Øµ: {datetime.now().strftime('%H:%M:%S')}")
                
                all_articles = []
                
                # Ø¬Ù„Ø¨ Ù…Ù† Ù…ØµØ§Ø¯Ø± RSS
                tasks = []
                for source_name, url in RSS_FEEDS:
                    tasks.append(fetch_rss_safe(session, url, source_name))
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, list):
                        all_articles.extend(result)
                
                # ØªØµÙÙŠØ© ÙˆØªØ±ØªÙŠØ¨
                important_articles = []
                general_articles = []
                
                for article in all_articles:
                    if article['type'] != "Ø¹Ø§Ù…":
                        important_articles.append(article)
                    else:
                        general_articles.append(article)
                
                # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ© ÙˆØ§Ù„ÙˆÙ‚Øª
                important_articles.sort(key=lambda x: x['timestamp'], reverse=True)
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹
                sent_count = 0
                for article in important_articles[:5]:  # Ø£ÙˆÙ„ 5 Ù…Ù‡Ù…Ø©
                    if article['id'] not in sent_articles:
                        success = await send_news_to_channel(bot, article)
                        if success:
                            sent_count += 1
                            await asyncio.sleep(2)  # Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø¹Ø§Ù…Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…Ù‡Ù…Ø©
                if sent_count == 0 and general_articles:
                    for article in general_articles[:3]:  # Ø£ÙˆÙ„ 3 Ø¹Ø§Ù…Ø©
                        if article['id'] not in sent_articles:
                            success = await send_news_to_channel(bot, article)
                            if success:
                                sent_count += 1
                                await asyncio.sleep(2)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                if len(sent_articles) > 100:
                    sent_articles.clear()
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                logging.info("=" * 60)
                logging.info(f"ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
                logging.info(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {len(all_articles)}")
                logging.info(f"   â­ Ø§Ù„Ù…Ù‡Ù…Ø©: {len(important_articles)}")
                logging.info(f"   ğŸ“° Ø§Ù„Ø¹Ø§Ù…Ø©: {len(general_articles)}")
                logging.info(f"   ğŸ“¤ Ø§Ù„Ù…Ø±Ø³Ù„Ø©: {sent_count}")
                logging.info("=" * 60)
                
            except Exception as e:
                logging.error(f"ğŸš¨ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø©: {e}")
            
            logging.info(f"â³ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± {CHECK_INTERVAL//60} Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„ÙØ­Øµ Ø§Ù„ØªØ§Ù„ÙŠ...")
            await asyncio.sleep(CHECK_INTERVAL)

def run_quick_check():
    """ÙØ­Øµ ÙŠØ¯ÙˆÙŠ Ø³Ø±ÙŠØ¹"""
    async def quick():
        try:
            bot = Bot(token=TELEGRAM_BOT_TOKEN)
            async with aiohttp.ClientSession() as session:
                logging.info("ğŸ” ÙØ­Øµ ÙŠØ¯ÙˆÙŠ Ø³Ø±ÙŠØ¹...")
                
                # Ø§Ø®ØªØ¨Ø§Ø± Ù…ØµØ¯Ø± ÙˆØ§Ø­Ø¯
                articles = await fetch_rss_safe(session, RSS_FEEDS[0][1], RSS_FEEDS[0][0])
                
                if articles:
                    logging.info(f"âœ… Ø§Ù„ÙØ­Øµ: {len(articles)} Ø®Ø¨Ø±")
                    for article in articles[:2]:
                        await send_news_to_channel(bot, article)
                        await asyncio.sleep(1)
                else:
                    logging.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø±")
                    
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ: {e}")
    
    asyncio.run(quick())

def start_bot_background():
    """Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(main_news_loop())

def run_flask_app():
    """ØªØ´ØºÙŠÙ„ Flask"""
    port = int(os.getenv('PORT', 10000))
    app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)

# ========== Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ==========
if __name__ == "__main__":
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    logging.info("=" * 70)
    logging.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø¨ÙˆØª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø§Ù„ÙŠØ©")
    logging.info(f"ğŸ“¢ Ø§Ù„Ù‚Ù†Ø§Ø©: {CHANNEL_USERNAME}")
    logging.info(f"â° ÙØªØ±Ø© Ø§Ù„ÙØ­Øµ: {CHECK_INTERVAL} Ø«Ø§Ù†ÙŠØ© ({CHECK_INTERVAL//60} Ø¯Ù‚ÙŠÙ‚Ø©)")
    logging.info(f"ğŸ“¡ Ù…ØµØ§Ø¯Ø± RSS: {len(RSS_FEEDS)}")
    logging.info("=" * 70)
    
    # Ø¨Ø¯Ø¡ Flask
    flask_thread = threading.Thread(target=run_flask_app, daemon=True)
    flask_thread.start()
    
    # ØªØ£Ø®ÙŠØ± Ø«Ù… Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª
    time.sleep(3)
    
    # Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª
    bot_thread = threading.Thread(target=start_bot_background, daemon=True)
    bot_thread.start()
    
    # Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙŠØ¹Ù…Ù„
    try:
        while True:
            time.sleep(3600)
    except KeyboardInterrupt:
        logging.info("ğŸ‘‹ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨ÙˆØª...")
